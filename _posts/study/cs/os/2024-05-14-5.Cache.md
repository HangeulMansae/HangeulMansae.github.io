---
layout: post
title: 05. Cache
categories: [study, cs, os]
tags: [blog]
---

- toc
{:toc .large-only}

## Cache

SRam의 속도와 DRam의 크기와 비용을 가지는 가상 메모리를 제공하는 것

- ### Locality

    - #### Temporal Locality (시간적)
      최근에 접근한 것은 다시 접근하게 될 확률이 높음
    - #### Spatial Locality (공간적)
      접근한 것의 주위 공간에 접근하게 될 확률이 높음
    
      - #### 지역성 예시
        2차원 행렬의 경우 메모리가 **인접한 열끼리 순차적으로 위치**하는데,     
        for문을 돌 때 가장 **안쪽 For문을 열로** 돌리면 곧 바로 옆의 것이 참조되어 **Hit Rate가 높아지지만**,     
        **행으로 돌리면** 근처의 것이 아니라 **Spatial Locality를 따르지 않아, Hit Rate가 떨어져**,     
        같은 반복문이더라도 **속도가 차이나게 됨**

- ### Mapping Function

  - #### Direct Mapping Mapping
    % 연산 등을 통해서 불러올 Memory 블럭마다 캐시의 어느 곳으로 갈 지 결정해서 할당하는 방식
    - #### 장점
      구현이 쉬움
    - #### 단점
      블럭이 들어가는 곳이 정해져 있기 때문에 우연히 같은 위치로 들어가는 Memory Load 연산이 반복된다면 Temporal Locality를 따르지 않을 수 있음 **(Hit rate이 떨어지는 이슈)**
  - #### N-Way Set Associative Mapping

    한 세트당 저장하는 블록 수를 N개로 조정

    이때 각 세트의 블럭 별로 사용하고 있는 값인지를 확인하는 Valid와 메모리의 나머지 부분을 저장하는 Tag 비트가 있음

    예를 들어 뒷자리 두비트로 하나의 Set를 만든다면 경우의 수는 00, 01, 10, 11 이렇게 네 경우가 있고, 앞으로 불러올 메모리의 하위 2bit를 보고서 저 4개 중 일치하는 곳의 Set 내의 블럭에 Load 함

    만약 블럭이 Valid한 곳이라면 Valid 하지 않은 블럭을 찾고 다 Valid하면 한 개를 비우고 넣음

    - #### 장점
      하나의 Set당 들어갈 수 있는 블록이 n개가 되므로 Hit rate이 늘어남
    - ### 단점
      탐색할 때 n개의 블럭을 다 찾아봐야 하므로 탐색 오버헤드가 발생함

  - #### Fully Associative Mapping
    N-Way Associative Mapping의 경우에서 한 세트에 모든 블럭을 넣는 것

- ### Cache 읽는 과정

  1. CPU로부터 읽을 메모리 주소 가져옴
  2. 메모리 블럭이 Cache에 담겨져 있는지 확인
  3. 있으면 바로 CPU에게 전달
  4. 없으면 메모리에서 블럭과 값을 값을 가져와서 Cache에 넣고, CPU에게 전달

- ### Cache 쓰는 방법
  - ### Write Through
    항상 데이터와 메모리 양쪽에 data를 write 함
    - ### 장점
      단순함
    - ### 단점
      느리고 메모리 트래픽 증가
  - ### Write Back
    Dirty Bit로 수정됐는지를 확인하고, 데이터를 캐시에만 Write 했다가 교체되어질 때, Write함
    - ### 장점
      빠름
    - ### 단점
      일관성을 검증하기가 까다로움